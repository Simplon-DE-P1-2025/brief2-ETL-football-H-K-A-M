# âš½ FIFA World Cup ETL Pipeline (1930â€“2022)

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-elephant)
![Pandas](https://img.shields.io/badge/Pandas-ETL-orange)
![Status](https://img.shields.io/badge/Status-Completed-green)

---

## Objectif du projet

Ce projet met en Å“uvre un **pipeline ETL (Extract â€“ Transform â€“ Load)** complet permettant de :

- centraliser **lâ€™historique exhaustif des matchs de Coupe du Monde FIFA (1930 â†’ 2022)** ;
- nettoyer et normaliser des donnÃ©es **hÃ©tÃ©rogÃ¨nes et bruitÃ©es** ;
- produire un dataset **fiable, cohÃ©rent et prÃªt pour lâ€™analyse et la base de donnÃ©es**.

Le pipeline est conÃ§u selon une logique **Data Engineer / Data Warehouse** :
- sÃ©paration claire des Ã©tapes,
- traÃ§abilitÃ© des donnÃ©es,
- rÃ¨gles mÃ©tier explicites,
- contrÃ´le qualitÃ© intÃ©grÃ©.

---

## Architecture globale

```mermaid
graph LR
    A[Sources brutes<br/>(CSV, JSON, TXT)] --> B[01â€“03<br/>Extraction]
    B --> C[04<br/>Unification]
    C --> D[05<br/>Enrichissement Kaggle]
    D --> E[06<br/>Nettoyage & RÃ©fÃ©rentiels]
    E --> F[07<br/>RÃ¨gles mÃ©tier]
    F --> G[08<br/>Chargement BDD]
    G --> H[(PostgreSQL<br/>Data Warehouse)]
```

Les donnÃ©es Ã©voluent selon les couches suivantes :

```
data/raw        -> donnÃ©es sources inchangÃ©es
data/processed  -> donnÃ©es unifiÃ©es et enrichies
data/clean      -> donnÃ©es prÃªtes analyse / base
data/reference  -> dimensions et rÃ©fÃ©rentiels
```

---

## Description dÃ©taillÃ©e des scripts

> Les scripts doivent Ãªtre exÃ©cutÃ©s **strictement dans lâ€™ordre**.

### 01_extract_preview.py â€” Exploration initiale

**RÃ´le** : audit des sources brutes.

- inspection des colonnes et types
- dÃ©tection des valeurs manquantes
- comprÃ©hension des schÃ©mas hÃ©tÃ©rogÃ¨nes

â¡ï¸ Script purement exploratoire (aucune Ã©criture disque).

---

### 02_extract_2022_from_text.py â€” Extraction 2022 (TXT)

**RÃ´le** : parser une source texte non structurÃ©e (Ã©dition 2022).

- parsing regex des lignes de matchs
- extraction : Ã©quipes, scores, dates, villes
- gestion des prolongations et penalties

â¡ï¸ Sortie : `data/processed/matches_2022.csv`

---

### 03_export_processed_csvs.py â€” Normalisation des formats

**RÃ´le** : convertir les sources 2018 (JSON) et autres formats exotiques en CSV standard.

- JSON â†’ DataFrame
- harmonisation minimale des colonnes

â¡ï¸ Objectif : prÃ©parer lâ€™unification globale.

---

### 04_unify_all_years.py â€” Fusion 1930 â†’ 2022

**RÃ´le** : construire le **dataset maÃ®tre**.

- chargement des Ã©ditions 1930â€“2010, 2014, 2018, 2022
- harmonisation du schÃ©ma
- gÃ©nÃ©ration dâ€™un premier `id_match`
- conservation volontaire des imperfections (dates placeholders, villes manquantes)

â¡ï¸ Sortie : `matches_unified_v1.csv`

---

### 05_v1-to-v2-kagglejson.py â€” Enrichissement Kaggle

**RÃ´le** : combler les manques via Kaggle (1930â€“2018).

- matching flou Ã©quipes / scores / Ã©ditions
- remplacement des dates fictives (`YYYY-01-01`)
- enrichissement des villes et phases

â¡ï¸ Sortie : `matches_unified_v2.csv`

---

### 06_v2-to-v3-clean.py â€” Nettoyage & rÃ©fÃ©rentiels

**RÃ´le clÃ© du projet**.

- normalisation **canonique** des Ã©quipes (IDs internes)
- suppression des faux pays (A1, Group B, etc.)
- crÃ©ation de tables de rÃ©fÃ©rence :
  - `dim_teams.csv`
  - `team_aliases.csv`
  - `unknown_teams.csv`
- normalisation complÃ¨te des phases (`round`)

Sortie principale : `matches_unified_v3.csv` (ID-based)

---

### 07_v3_to_v4_ready_for_db.py â€” RÃ¨gles mÃ©tier finales

**RÃ´le** : prÃ©parer les donnÃ©es pour la base de donnÃ©es.

Principales rÃ¨gles :

#### is_final

```text
True  -> tournoi final (Group â†’ Final)
False -> qualifications / preliminary rounds
```

â¡ï¸ Permet de filtrer instantanÃ©ment lâ€™historique officiel (~900 matchs).

#### Edition

- transformation : `"1930-URUGUAY" â†’ 1930`
- type : entier

#### RÃ©sultat DB-friendly

- `draw` ou `team_id` gagnant

Sortie : `matches_unified_v4.csv`

---

### ğŸ—„ï¸ 08_v4_to_db.py â€” Chargement PostgreSQL

**RÃ´le** : injection finale en base.

- crÃ©ation des tables
- chargement des dimensions (`teams`)
- chargement des faits (`matches`)
- vÃ©rification des contraintes

---

## ModÃ¨le de donnÃ©es cible

### Table `matches`

| Colonne | Description |
|------|------------|
| id_match | PK |
| home_team_id | FK team |
| away_team_id | FK team |
| home_result | Score |
| away_result | Score |
| result | draw ou team_id |
| date | Date ISO |
| round | Phase normalisÃ©e |
| edition | AnnÃ©e |
| is_final | Filtre mÃ©tier |

---

### ğŸ§© Table `teams`

| Colonne | Description |
|------|------------|
| team_id | PK |
| team_canonical | Nom officiel |
| iso2 | Code ISO |
| iso3 | Code ISO |

---

## ğŸš€ Installation & exÃ©cution

```bash
git clone https://github.com/your-repo/fifa-etl.git
cd fifa-etl
pip install -r requirements.txt
```

Configurer `.env` puis exÃ©cuter les scripts **dans lâ€™ordre**.

---

## ğŸ§  CompÃ©tences dÃ©montrÃ©es

- ETL Python avancÃ© (pandas)
- Data Quality & normalisation sÃ©mantique
- ModÃ©lisation Data Warehouse
- Gestion des rÃ©fÃ©rentiels
- Pipeline traÃ§able et maintenable

---

## ğŸ“Œ Contexte acadÃ©mique

Projet rÃ©alisÃ© dans le cadre de la formation **Data Engineer** â€” DÃ©cembre 2025.

