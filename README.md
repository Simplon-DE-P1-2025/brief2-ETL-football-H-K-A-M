# brief2-ETL-football-H-K-A-M
Brief 2 : ETL pour analyser des donn√©es footballistique

# Contexte et objectifs du projet
Ce projet vise √† construire un pipeline ETL en Python pour centraliser l'historique des matchs de Coupe du Monde FIFA (1930‚Äì2022), nettoyer les donn√©es et charger un dataset propre dans une base PostgreSQL afin d'alimenter des analyses (KPI) et, √† terme, un mod√®le d'estimation des probabilit√©s de victoire entre deux √©quipes.

**‚úÖ OBJECTIFS ATTEINTS :**
- **6861 matchs** de Coupe du Monde consolid√©s (1930-2022)
- **227 √©quipes** nationales r√©f√©renc√©es
- **Base PostgreSQL** op√©rationnelle sur Render Cloud
- **4 tables normalis√©es** pour optimiser les analyses
- **Pipeline ETL complet** avec 9 scripts automatis√©s
- **Visualisations interactives** avec insights m√©tier

Les sources incluent les fichiers fournis (1930‚Äì2010, 2014, 2018) et l‚Äô√©dition 2022 (Kaggle).

# √âquipe et organisation

√âquipe: Hafida, Khalid, Ali, Mohammed
Chef de projet: Hafida


# Processus de gestion de projet

en cours

##  Tableau de gestion de projet

| T√¢che | Responsable | √âch√©ance | Statut |
|-------|-------------|----------|--------|
| Clonage du repo et setup | All | 15/12 | ‚úÖ **Fait** |
| Cr√©ation Projects + t√¢ches | K | 15/12 | ‚úÖ **Fait** |
| D√©finition outils + hypoth√®ses | √âquipe | 15/12 | ‚úÖ **Fait** |
| Observation des donn√©es (01_extract_preview.py) | M | 16/12 | ‚úÖ **Fait** |
| Extraction 1930‚Äì2010/2014/2018 (02-03) | √âquipe | 17/12 | ‚úÖ **Fait** |
| Recherche/Int√©gration 2022 (04_unify_all_years.py) | √âquipe | 17/12 | ‚úÖ **Fait** |
| Enrichissement Kaggle (05_v1-to-v2-kagglejson.py) | √âquipe | 18/12 | ‚úÖ **Fait** |
| Nettoyage et harmonisation (06-07) | √âquipe | 18/12 | ‚úÖ **Fait** |
| Sch√©ma BDD et chargement (08-09 + run_setup.py) | √âquipe | 19/12 | ‚úÖ **Fait** |
| Requ√™tes KPI et visualisations | √âquipe | 19/12 | ‚úÖ **Fait** |
| Rapport et documentation | √âquipe | 19/12 | ‚úÖ **Fait** |


# Stack technique utilis√©e

**‚úÖ ARCHITECTURE DEPLOY√âE :**

- **Langage** : Python 3.x
- **Biblioth√®ques ETL** : pandas, numpy, sqlalchemy, psycopg2-binary
- **Base de donn√©es** : **PostgreSQL sur Render Cloud** (gratuit, accessible √©quipe)
- **Visualisations** : plotly, matplotlib, seaborn (Jupyter Notebook)
- **Gestion de versions** : Git + GitHub
- **Collaboration** : GitHub Projects (Kanban), Issues
- **Nettoyage & ETL** : pandas, unidecode, python-dateutil, requests
- **Infrastructure** : Classe `DatabaseManager` r√©utilisable
- **Documentation** : README, rapport technique complet, visualisations interactives

**üéØ CHOIX TECHNIQUE :**
- **PostgreSQL Render** : Solution cloud gratuite, accessible par toute l'√©quipe
- **4 tables normalis√©es** : Optimisation des performances SQL
- **Pipeline modulaire** : 9 scripts ETL s√©quentiels pour tra√ßabilit√© compl√®te


# Donn√©es et sources

    Fichiers fournis:

        matches_19302010.csv (historique 1930‚Äì2010)

        WorldCupMatches2014.csv (√©dition 2014)

        data_2018.json (√©dition 2018)

    √âdition 2022: dataset Kaggle ‚ÄúFIFA World Cup 2022 Match Data‚Äù (matchs complets).

# Les branches / Etapes de travail

## Branche Observation des donn√©es

    But : explorer et comprendre la structure des datasets.

    Actions typiques :

        -- Lire les donn√©es

        --Afficher les colonnes (print(df.columns)).
        --Lister les colonnes et leurs types
        --Classer les colonnes
        --Faire un tableau de correspondance des colonnes

        --V√©rifier les types (df.dtypes)
        --les valeurs uniques
        --Observer les valeurs manquantes
        --Rep√©rer les doublons
        --les √©ventuelles incoh√©rences
             --Ann√©es manquantes
             --Confusion entre NaN et 0.

##  Enrichissement des donn√©es

    Recherche de nouvelles donn√©es suite a observations de donn√©es manquantes
    extraction de fichier texte

## Nettoyage et Transformation des donn√©es
    Fonction de cleannage es csv et de transformation

### FIFA World Cup ETL Pipeline (1930‚Äì2022)

Met en ≈ìuvre un **pipeline ETL (Extract ‚Äì Transform ‚Äì Load)** complet permettant de :

- centraliser **l‚Äôhistorique exhaustif des matchs de Coupe du Monde FIFA (1930 ‚Üí 2022)** ;
- nettoyer et normaliser des donn√©es **h√©t√©rog√®nes et bruit√©es** ;
- produire un dataset **fiable, coh√©rent et pr√™t pour l‚Äôanalyse et la base de donn√©es**.

Le pipeline est con√ßu selon une logique **Data Engineer / Data Warehouse** :
- s√©paration claire des √©tapes,
- tra√ßabilit√© des donn√©es,
- r√®gles m√©tier explicites,
- contr√¥le qualit√© int√©gr√©.

---

### Architecture globale

Les donn√©es √©voluent selon les couches suivantes :

```
data/raw        -> donn√©es sources inchang√©es
data/processed  -> donn√©es unifi√©es et enrichies
data/clean      -> donn√©es pr√™tes analyse / base
data/reference  -> dimensions et r√©f√©rentiels
```

---

# Description d√©taill√©e d'excution du Pipeline

> Les scripts doivent √™tre ex√©cut√©s **strictement dans l‚Äôordre**.

### 01_extract_preview.py ‚Äî Exploration initiale

**R√¥le** : audit des sources brutes.

- inspection des colonnes et types
- d√©tection des valeurs manquantes
- compr√©hension des sch√©mas h√©t√©rog√®nes

--> Script purement exploratoire (aucune √©criture disque).

---

### 02_extract_2022_from_text.py ‚Äî Extraction 2022 (TXT)

**R√¥le** : parser une source texte non structur√©e (√©dition 2022).

- parsing regex des lignes de matchs
- extraction : √©quipes, scores, dates, villes
- gestion des prolongations et penalties

--> Sortie : `data/processed/matches_2022.csv`

---

### 03_export_processed_csvs.py ‚Äî Normalisation des formats

**R√¥le** : convertir les sources 2018 (JSON) et autres formats exotiques en CSV standard.

- JSON ‚Üí DataFrame
- harmonisation minimale des colonnes

--> Objectif : pr√©parer l‚Äôunification globale.

---

### 04_unify_all_years.py ‚Äî Fusion 1930 ‚Üí 2022

**R√¥le** : construire le **dataset ma√Ætre**.

- chargement des √©ditions 1930‚Äì2010, 2014, 2018, 2022
- harmonisation du sch√©ma
- g√©n√©ration d‚Äôun premier `id_match`
- conservation volontaire des imperfections (dates placeholders, villes manquantes)

--> Sortie : `matches_unified_v1.csv`

---

### 05_v1-to-v2-kagglejson.py ‚Äî Enrichissement Kaggle

**R√¥le** : combler les manques via Kaggle (1930‚Äì2018).

- matching flou √©quipes / scores / √©ditions
- remplacement des dates fictives (`YYYY-01-01`)
- enrichissement des villes et phases

--> Sortie : `matches_unified_v2.csv`

---

### 06_v2-to-v3-clean.py ‚Äî Nettoyage & r√©f√©rentiels

**R√¥le cl√© du projet**.

- normalisation **canonique** des √©quipes (IDs internes)
- suppression des faux pays (A1, Group B, etc.)
- cr√©ation de tables de r√©f√©rence :
  - `dim_teams.csv`
  - `team_aliases.csv`
  - `unknown_teams.csv`
- normalisation compl√®te des phases (`round`)

Sortie principale : `matches_unified_v3.csv` (ID-based)

---

### 07_v3_to_v4_ready_for_db.py ‚Äî R√®gles m√©tier finales

**R√¥le** : pr√©parer les donn√©es pour la base de donn√©es.

Principales r√®gles :

#### is_final

```text
True  -> tournoi final (Group ‚Üí Final)
False -> qualifications / preliminary rounds
```

--> Permet de filtrer instantan√©ment l‚Äôhistorique officiel (~900 matchs).

#### Edition

- transformation : `"1930-URUGUAY" ‚Üí 1930`
- type : entier

#### R√©sultat DB-friendly

- `draw` ou `team_id` gagnant

Sortie : `matches_unified_v4.csv`

---

### 08_v4_to_db.py ‚Äî Version analytique finale

**R√¥le** : cr√©er la version finale orient√©e analyse m√©tier.

- d√©normalisation pour BI (IDs ‚Üí noms de pays)
- traduction du r√©sultat en "business logic" 
- segmentation strat√©gique (`is_final`)
- dataset final pr√™t visualisations

### 09_tables_construction.py ‚Äî Mod√©lisation relationnelle

**R√¥le** : transformer en mod√®le relationnel normalis√©.

- mod√©lisation avec s√©paration domicile/ext√©rieur  
- optimisation performances SQL avec jointures rapides
- 4 tables normalis√©es haute performance

### run_setup.py ‚Äî Chargement PostgreSQL Render

**R√¥le** : injection finale en base cloud.

- cr√©ation des tables PostgreSQL sur Render
- chargement des 4 tables normalis√©es
- validation et contr√¥les qualit√© finaux

---

## Mod√®le de donn√©es d√©ploy√©

**üóÑÔ∏è BASE POSTGRESQL OP√âRATIONNELLE (Render Cloud)**

### **Architecture : 4 tables normalis√©es**

#### 1. Table `teams_reference` (227 √©quipes)
| Colonne | Description |
|---------|-------------|
| team_id | PK - Identifiant unique |
| team_name | Nom canonique officiel |
| iso_code | Code ISO pays |

#### 2. Table `matches_normalized` (6861 matchs)
| Colonne | Description |
|---------|-------------|
| match_id | PK - Identifiant s√©quentiel |
| date | Date du match (format ISO) |
| round | Phase normalis√©e (Group, Final, etc.) |
| city | Ville du match |
| edition | Ann√©e de la Coupe du Monde |
| result | ID √©quipe gagnante ou "draw" |

#### 3. Table `home_stats` (Statistiques domicile)
| Colonne | Description |
|---------|-------------|
| match_id | FK vers matches_normalized |
| home_team_id | FK vers teams_reference |
| home_score | Buts marqu√©s √† domicile |

#### 4. Table `away_stats` (Statistiques ext√©rieur)
| Colonne | Description |
|---------|-------------|
| match_id | FK vers matches_normalized |
| away_team_id | FK vers teams_reference |
| away_score | Buts marqu√©s √† l'ext√©rieur |

---

##  Installation & ex√©cution

```bash
git clone https://github.com/your-repo/fifa-etl.git
cd fifa-etl
pip install -r requirements.txt
```

Configurer `.env` puis ex√©cuter les scripts **dans l‚Äôordre**.

---

##  Comp√©tences d√©montr√©es

- ETL Python avanc√© (pandas)
- Data Quality & normalisation s√©mantique
- Mod√©lisation Data Warehouse
- Gestion des r√©f√©rentiels
- Pipeline tra√ßable et maintenable

---

##  Contexte acad√©mique

Projet r√©alis√© dans le cadre de la formation **Data Engineer** ‚Äî D√©cembre 2025
